{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT40800 Data Programming with Python\n",
    "## Dr. Áine Byrne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9\n",
    "\n",
    "This week we cover statistical modelling in Python. We'll begin with basic statistical tests in scipy.\n",
    "Before moving on to the statsmodels package to explore a linear regression and a logistic regression.\n",
    "\n",
    "Unfortunately, the documentation (especially examples) for statistical modelling in Python is limited. Extra reading for this lecture includes the [scipy stats tutorial](docs.scipy.org/doc/scipy/reference/tutorial/stats.html) and the\n",
    "[statsmodels documentation](statsmodels.sourceforge.net/stable/index.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week we will use two data sets from Elements of Statistical Learning by Hastie, Tibshirani and Friedman.\n",
    "\n",
    "* The first is the prostate dataset, which contains information about prostate cancer patients. The response variable is the log of the prostate specific antigen, while the explanatory variables are things like age, weight and cancer size. \n",
    "* The second is the South African heart disease dataset. The response variable is a Boolean, indicating whether or not the subject has heart disease. The explanatory variables include age, systolic blood pressure and tobacco consumption.\n",
    "\n",
    "We will load them in directly from their web address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate = pd.read_csv('http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data',sep='\\t')\n",
    "SA = pd.read_csv('http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by having a look at the prostate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prostate.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going any further, we will need to standardise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate_numeric = prostate.drop(['Unnamed: 0','train'],axis=1)\n",
    "prostate_std = (prostate_numeric-prostate_numeric.mean())/prostate_numeric.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prostate_std.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data standardised, it is easy to identify outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prostate_std[(np.abs(prostate_std)>3).any(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `any(x)` method finds every row where this is at least x Trues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "Standardise the South African heart disease dataset and identify any outliers that are at least 4 standard deviations away from the mean. How many of these outliers are there in the tobacco column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "Most advanced stats is shared between the scipy.stats and statsmodels modules. We'll begin by looking at scipy.stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-sample t-test\n",
    "\n",
    "Let's see whether lpsa (log prostate specific antigen - the key\n",
    "response variable) is significantly different between those aged\n",
    "65 and under versus those aged over 65.\n",
    "\n",
    "We first need to split the data into two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpsa_gt_65 = prostate.lpsa[prostate.age>65]\n",
    "lpsa_lt_65 = prostate.lpsa[prostate.age<=65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can run an independent two-sample t-test, using the scipy.stats function `ttest_ind`. The input arguments are the two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(lpsa_gt_65, lpsa_lt_65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a tuple of length 2, with the t-statistic followed by the p-value. The default is to assume equal varaince, for unequal variance inlcude the input argument `equal_var=False`. We should also note that scipy.stats only performs two-sided tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "Run a t-test with unequal variances on the lpsa data set to see whether there is a significant difference between the training (`train='T'`) and test (`train='F'`) set. What is the p-value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mann Whitney U test\n",
    "\n",
    "The t-test assumes that the sample is drawn from a normal distribution. If that is not the case, we must use a\n",
    "non-parametric hypothesis test. The Mann Whitney U test is a non-parametric test, which makes no assumptions about the distribution of the data being sampled.\n",
    "\n",
    "To run a Mann Whitney U test use the scipy.stats function `mannwhitneyu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(lpsa_gt_65, lpsa_lt_65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the t-test this returns the test statistic value followed by the p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolmogorov-Smirnov\n",
    "\n",
    "Suppose we want to check the shape of the distribution of lpsa. We should probably start by creating a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "prostate.lpsa.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run a Kolmogorov-Smirnov test to test the distribution shape, using the scipt.stats command `kstest`. The first argument is the data we wish to test and the second is the name of the distribution we wish to test it against. A list of scipy.stats distributions and their names can be found [here](https://docs.scipy.org/doc/scipy/reference/stats.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kstest(prostate.lpsa, 'norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is significant, i.e. the data is not match a standard normal distribution. However, if we se the standardised data, the result is not significant, indicating that the data is normally distibuted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kstest(prostate_std.lpsa, 'norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "The scipy.stats function `pearsonr` performs a statistical test to determine whether or not two variables are linearly dependent. Read the function help file/documentation and use it to test whether the `lpsa` and `lweight` variables are linearly dependent. What is the p-value? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QQ-plots\n",
    "\n",
    "QQ-plots are useful for comparing data to theoretical distributions. In particular, they are great for checking the tails of the distribution. The idea is to plot the data against theoretical quantiles for a\n",
    "distribution. If the data matches the distribution we should have a straight line.\n",
    "\n",
    "To create a QQ-plot with scipy.stats, use the `probplot` command. By default the function only returns the values and does not plot them. To create a plot, include the argument `plot=plt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "stats.probplot(prostate.lpsa, dist='norm',plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "The statsmodels package runs lots of different statistical\n",
    "modelling techniques: linear regression, generalised linear\n",
    "models, ANOVA, time series models, etc\n",
    "\n",
    "We'll start with linear regression. Structure:\n",
    "$$ y = X\\beta + \\epsilon\\hspace{0.1cm}; \\hspace{0.5cm}\\epsilon \\sim N(0,\\sigma^2) $$\n",
    "\n",
    "Typically, we use least squares or maximum likelihood to find the $\\beta$ that fits the data best.\n",
    "\n",
    "\n",
    "In the statsmodels documentation X are called the exogenous variables and y the\n",
    "endogenous variable.\n",
    "\n",
    "The original way to fit a linear regression in statsmodels is via\n",
    "the `OLS` function from the api module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(prostate_std.lpsa,prostate_std.drop('lpsa',axis=1))\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives lots of fitting details, but notice it contains no intercept term! If using the api `OLS` function, you need to add an intercept column to the exogenous/explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_const = prostate_std.drop('lpsa',axis=1)\n",
    "X_with_const.insert(0,'intercept',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.OLS(prostate_std.lpsa,X_with_const)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For anyone who has used R before, you may be more comfortable with the other method for fitting a linear regression model using statsmodels. This is done via the `ols` function from the formula.api module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "mod2 = smf.ols(formula='lpsa ~ lcavol + lweight + age', data=prostate_std)\n",
    "res2 = mod2.fit()\n",
    "print(res2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method includes an intercept by default. You should read through the help files for `ols` and `fit` to see all of the available input arguments. Additional arguments include `method` which allows you change the fitting method and `subset` which assigns the subset of data to be used in the model it.\n",
    "\n",
    "In general, use method 2 where you have small numbers of\n",
    "explanatory (exogenous) variables, and method 1 where you\n",
    "have large numbers. In addition, method 2 allows you to easily include interaction terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3 = smf.ols(formula='lpsa ~ lcavol* lweight * age', data=prostate_std)\n",
    "res3 = mod3.fit()\n",
    "print(res3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also include categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate_std['age_lt_65'] = prostate.age<65\n",
    "mod4 = smf.ols(formula='lpsa ~ lcavol + lweight + C(age_lt_65)', data=prostate_std).fit()\n",
    "print(mod4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While adding a `-1` to you formula will remove the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod5 = smf.ols(formula='lpsa ~ lcavol + lweight + C(age_lt_65) -1', data=prostate_std).fit()\n",
    "print(mod5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can add functions of the variable to the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod6 = smf.ols(formula='lpsa ~ lcavol + pow(lcavol,2)', data=prostate_std).fit()\n",
    "print(mod6.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of attributes and methods that can be applied to the model fit (`mod6` in last example). You can type the name of the model fit followed by a fullstop and hit the tab key, or use the `dir` function to see all of the available methods and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(mod6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A particularly useful attribure is `resid` which returns the residuals of the model fit. One assumption of a linear regression model is that the variance of the residual is the same for all values of X. We can verify this by plotting the model prediction against the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_summary = DataFrame({'preds':mod6.predict(),'resids':mod6.resid})\n",
    "mod_summary.plot('preds','resids',kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4\n",
    "The code below splits the prostate dataset into training and test sets, and fits a linear regression model to the training set only. \n",
    "\n",
    "Use the `predict` method to predict the `lpsa` for the test set, using the model fit for the training data. Plot the predictions against the true `lpsa` and compute the correlation between them. Is the model a good fit?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prostate_std[prostate.train=='T']\n",
    "test_data = prostate_std[prostate.train=='F']\n",
    "train_model = smf.ols(formula='lpsa ~ lcavol + pow(lcavol,2)', data=train_data).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "Logistic regression is exactly the same as standard linear\n",
    "regression except that the response variable (endogenous\n",
    "variable) is binary and treated as Bernoulli distributed variable\n",
    "$$y_i \\sim \\text{Bernoulli}(p_i)\\hspace{0.1cm}; \\hspace{0.5cm}\\text{logit}(p_i) = X\\beta$$\n",
    "where $\\text{logit}(z) = log(z/(1-z))$. The model is usually fit via maximum\n",
    "likelihood.\n",
    "\n",
    "![title](linear-regression-vs-logistic-regression.png)\n",
    "\n",
    "Taken from: https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-vs-logistic-regression.png\n",
    "\n",
    "For this section we will use the SA heart disease dataset. We'll have a quick look at the data and standardise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_numeric = SA.drop(['row.names','famhist','chd'],axis=1)\n",
    "SA_std = (SA_numeric-SA_numeric.mean())/SA_numeric.std()\n",
    "SA_std.insert(0,'intercept',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should do some plotting and other exploratory data analysis steps here. \n",
    "\n",
    "To perform a logistic regression model, we use the `Logit` function from the api module. The syntax is the same as for the `OLS` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit1 = sm.Logit(SA.chd, SA_std).fit()\n",
    "print(logit1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial values suggest age, tobacco, ldl cholesterol, and type a behaviour are the most important variables. Remember that these coefficients are given on the logit scale. \n",
    "As before loads of other methods and attributes can be found using `dir(logit1)` or `logit1.` and the tab key.\n",
    "\n",
    "Age seems to be the most important variable, so we will re-fit with age only and then make a prediction for a range of new values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit2 = sm.Logit(SA.chd, SA_std['age']).fit()\n",
    "new_age = DataFrame({'age': np.linspace(-3,3,100)})\n",
    "new_preds = logit2.predict(new_age)\n",
    "new_age['preds'] = new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "new_age.plot('age','preds')\n",
    "plt.plot(SA_std['age'],SA.chd,'r+')\n",
    "plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a strong relationship, despite being the most significant variable.\n",
    "\n",
    "The model predictions the probability of a person with a particular age (in terms of standard deviations away from the mean) having heart disease. To classify the success of our model fit, we set a cut-off value as with the Week 8 assessed exercises. For a logistic regression model, the cut-off is typically set at 0.5. We will look at this in more detail next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the smf formula interface to fit a logistic regression model. The code below performs a logistic regression using the variables `sbp` and `tobacco`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_smf = smf.logit(formula='chd ~ sbp + tobacco + famhist', data=SA).fit()\n",
    "print(logit_smf.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5\n",
    "Fit each of the models below to the SA heart disease data. Which relationship results in the best fit (has the highest Pseudo-R$^2$ value)?\n",
    "* 'chd ~ adiposity + tobacco + ldl'\n",
    "* 'chd ~ sbp + tobacco + famhist'\n",
    "* 'chd ~ adiposity + tobacco'\n",
    "* 'chd ~ tobacco + ldl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}